{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3b4cb9",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATASET_PATH = BASE_DIR / \"dataset_filtered\"\n",
    "LABEL_MAP = BASE_DIR / \"label_map.txt\"\n",
    "MODEL_NAME = BASE_DIR / \"crop_disease_model.keras\"\n",
    "EPOCHS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8979ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset folder not found at {DATASET_PATH}\\n\"\n",
    "        \"Please download the dataset and place it in the project root as 'dataset_filtered/'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac4a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d57a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6961d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16254 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26dd404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4058 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = val_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08aec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label map saved to d:\\Lohith\\BTECH CODES\\Machine_Learning\\Project\\Crop-Disease\\label_map.txt\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = train_data.num_classes\n",
    "labels = train_data.class_indices\n",
    "with open(LABEL_MAP, \"w\") as f:\n",
    "    for label, idx in labels.items():\n",
    "        f.write(f\"{idx}:{label}\\n\")\n",
    "\n",
    "print(\"âœ… Label map saved to\", LABEL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c0730",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURE AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c6d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f20e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c809fd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m327,936\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             â”‚         \u001b[38;5;34m3,341\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,589,261</span> (9.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,589,261\u001b[0m (9.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,277</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,277\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bba55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(1.5628846153846154), 1: np.float64(1.5628846153846154), 2: np.float64(10.2484237074401), 3: np.float64(0.7346108650456477), 4: np.float64(1.5628846153846154), 5: np.float64(0.8182641965364479), 6: np.float64(1.6408237431859478), 7: np.float64(0.8823625210357744), 8: np.float64(0.9323696437790397), 9: np.float64(1.1123733917328222), 10: np.float64(0.29171901360422126), 11: np.float64(4.181631077952148), 12: np.float64(0.9821741494954378)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_data.classes),\n",
    "    y=train_data.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c568a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(MODEL_NAME, save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4765566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 689ms/step - accuracy: 0.6721 - loss: 1.0749 - val_accuracy: 0.8418 - val_loss: 0.5188 - learning_rate: 3.0000e-04\n",
      "Epoch 2/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 384ms/step - accuracy: 0.8196 - loss: 0.5672 - val_accuracy: 0.8659 - val_loss: 0.4142 - learning_rate: 3.0000e-04\n",
      "Epoch 3/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 375ms/step - accuracy: 0.8522 - loss: 0.4656 - val_accuracy: 0.8667 - val_loss: 0.3847 - learning_rate: 3.0000e-04\n",
      "Epoch 4/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 385ms/step - accuracy: 0.8666 - loss: 0.4127 - val_accuracy: 0.8891 - val_loss: 0.3305 - learning_rate: 3.0000e-04\n",
      "Epoch 5/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 393ms/step - accuracy: 0.8794 - loss: 0.3702 - val_accuracy: 0.8783 - val_loss: 0.3492 - learning_rate: 3.0000e-04\n",
      "Epoch 6/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 382ms/step - accuracy: 0.8858 - loss: 0.3491 - val_accuracy: 0.8928 - val_loss: 0.3064 - learning_rate: 3.0000e-04\n",
      "Epoch 7/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 436ms/step - accuracy: 0.8880 - loss: 0.3324 - val_accuracy: 0.8901 - val_loss: 0.3065 - learning_rate: 3.0000e-04\n",
      "Epoch 8/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 626ms/step - accuracy: 0.8948 - loss: 0.3202 - val_accuracy: 0.8940 - val_loss: 0.2942 - learning_rate: 3.0000e-04\n",
      "Epoch 9/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 384ms/step - accuracy: 0.9019 - loss: 0.2975 - val_accuracy: 0.8958 - val_loss: 0.2922 - learning_rate: 3.0000e-04\n",
      "Epoch 10/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 384ms/step - accuracy: 0.9029 - loss: 0.2865 - val_accuracy: 0.9096 - val_loss: 0.2569 - learning_rate: 3.0000e-04\n",
      "Epoch 11/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 384ms/step - accuracy: 0.9085 - loss: 0.2771 - val_accuracy: 0.9105 - val_loss: 0.2628 - learning_rate: 3.0000e-04\n",
      "Epoch 12/12\n",
      "\u001b[1m508/508\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 382ms/step - accuracy: 0.9135 - loss: 0.2595 - val_accuracy: 0.9115 - val_loss: 0.2582 - learning_rate: 3.0000e-04\n",
      "Final Training Accuracy: 0.9134982228279114\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "print(\"Final Training Accuracy:\", history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94ddc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final model saved\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)\n",
    "print(\"âœ… Final model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f40fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "with open(LABEL_MAP, \"r\") as f:\n",
    "    for line in f:\n",
    "        idx, label = line.strip().split(\":\")\n",
    "        label_map[int(idx)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82658ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMEDIATION_DB = {\n",
    "    \"Potato___Early_blight\": {\n",
    "        \"organic\": {\n",
    "            \"urgency\": \"Monitor & apply organic remedies.\",\n",
    "            \"steps\": [\n",
    "                \"Remove infected leaves\",\n",
    "                \"Spray neem oil\",\n",
    "                \"Improve air circulation\"\n",
    "            ],\n",
    "            \"dosage\": \"3 ml/L\",\n",
    "            \"frequency\": \"Once every 7 days\",\n",
    "            \"max_limit\": \"Do not exceed 5 ml/L\",\n",
    "            \"base_cost\": (100, 250)   # ğŸ”¥ NEW\n",
    "        },\n",
    "        \"chemical\": {\n",
    "            \"urgency\": \"Apply fungicide immediately.\",\n",
    "            \"steps\": [\n",
    "                \"Spray Mancozeb\",\n",
    "                \"Repeat after 7 days\",\n",
    "                \"Avoid irrigation for 24 hours\"\n",
    "            ],\n",
    "            \"dosage\": \"2 g/L\",\n",
    "            \"frequency\": \"Once every 7 days\",\n",
    "            \"max_limit\": \"Do not exceed 3 g/L\",\n",
    "            \"base_cost\": (250, 600)   # ğŸ”¥ NEW\n",
    "        },\n",
    "        \"prevention\": [\n",
    "            \"Avoid overhead irrigation\",\n",
    "            \"Use disease-resistant varieties\",\n",
    "            \"Crop rotation\"\n",
    "        ],\n",
    "        \"safety\": [\n",
    "            \"Wear gloves & mask\",\n",
    "            \"Do not spray during noon\",\n",
    "            \"Keep away from children\"\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6162aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 13), dtype=float32, numpy=\n",
       "array([[2.3558036e-06, 2.7145757e-07, 1.5208500e-06, 5.6277501e-04,\n",
       "        1.3047788e-05, 9.9529147e-01, 2.1486147e-05, 2.9396375e-03,\n",
       "        3.5104102e-05, 1.7340095e-05, 7.0359831e-04, 1.2451320e-05,\n",
       "        3.9906017e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(MODEL_NAME)\n",
    "\n",
    "dummy_input = np.zeros((1, 224, 224, 3), dtype=np.float32)\n",
    "model(dummy_input)  # ğŸ‘ˆ IMPORTANT: call model directly, not predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a585647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blurry(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    variance = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    threshold = 100.0  # You can adjust this threshold\n",
    "    return variance < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0699a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradcam(model, img_path, layer_name=None):\n",
    "    \"\"\"Generate a Grad-CAM heatmap overlay for the predicted class.\n",
    "\n",
    "    Fixes Keras graph issues by building the Grad-CAM model using the\n",
    "    MobileNetV2 base model's input graph (not Sequential's symbolic tensors).\n",
    "    \"\"\"\n",
    "    base_model = model.layers[0]  # MobileNetV2 (Functional)\n",
    "\n",
    "    # Pick a sensible conv layer if not provided\n",
    "    if layer_name is None:\n",
    "        for layer in reversed(base_model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer_name = layer.name\n",
    "                break\n",
    "        if layer_name is None:\n",
    "            # Fallback: any layer with 'conv' in its name\n",
    "            for layer in reversed(base_model.layers):\n",
    "                if \"conv\" in layer.name.lower():\n",
    "                    layer_name = layer.name\n",
    "                    break\n",
    "\n",
    "    if layer_name is None:\n",
    "        raise ValueError(\"No convolutional layer found in base model.\")\n",
    "\n",
    "    conv_layer = base_model.get_layer(layer_name)\n",
    "\n",
    "    # Build a Grad-CAM graph rooted at base_model.input to avoid tensor mismatch\n",
    "    x = base_model.output\n",
    "    for head_layer in model.layers[1:]:\n",
    "        x = head_layer(x)\n",
    "    preds = x\n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=[conv_layer.output, preds],\n",
    "    )\n",
    "\n",
    "    # Load and preprocess image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0).astype(np.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(pooled_grads * conv_outputs, axis=-1)\n",
    "\n",
    "    # Convert to numpy once, then use numpy/cv2 safely\n",
    "    heatmap = heatmap.numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= (np.max(heatmap) + 1e-8)\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (224, 224))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    original = cv2.imread(img_path)\n",
    "    if original is None:\n",
    "        raise FileNotFoundError(f\"Could not read image from path: {img_path}\")\n",
    "    original = cv2.resize(original, (224, 224))\n",
    "\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(original, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    output_path = \"heatmap_output.jpg\"\n",
    "    cv2.imwrite(output_path, overlay)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9769f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_real_lesion_boxes(img_path):\n",
    "    original = cv2.imread(img_path)\n",
    "    if original is None:\n",
    "        raise FileNotFoundError(\"Image not found\")\n",
    "\n",
    "    hsv = cv2.cvtColor(original, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Brown / yellow lesion color range\n",
    "    lower = np.array([5, 40, 40])\n",
    "    upper = np.array([35, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    # Morph cleanup\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 250:  # reject noise\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w > 15 and h > 15:\n",
    "                boxes.append((x, y, w, h))\n",
    "\n",
    "    # Draw boxes\n",
    "    for (x, y, w, h) in boxes:\n",
    "        cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    output_path = \"boxed_output.jpg\"\n",
    "    cv2.imwrite(output_path, original)\n",
    "\n",
    "    return output_path, len(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "80bc4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disease(img_path, confidence_threshold=0.45):\n",
    "    if is_blurry(img_path):\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": \"Image is too blurry. Please retake photo.\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    \n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    preds = model.predict(img_array)[0]\n",
    "    top_idx = np.argmax(preds)\n",
    "    confidence = float(preds[top_idx])\n",
    "    disease_name = label_map[top_idx]\n",
    "\n",
    "    # Epic 3: Unknown/Unclear Result Story\n",
    "    if confidence < confidence_threshold:\n",
    "        return {\n",
    "            \"status\": \"unknown\",\n",
    "            \"disease\": \"Unknown/Unclear\",\n",
    "            \"message\": \"Please consult a human expert or retake the photo.\",\n",
    "            \"confidence\": round(confidence * 100, 2)\n",
    "        }\n",
    "    \n",
    "    # Epic 3: Healthy Plant Story\n",
    "    # Check if the predicted label contains the word \"healthy\"\n",
    "    is_healthy = \"healthy\" in disease_name.lower()\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"disease\": disease_name,\n",
    "        \"is_healthy\": is_healthy,\n",
    "        \"confidence\": round(confidence * 100, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3ecc9fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 0.9134982228279114\n",
      "Final Validation Accuracy: 0.9115327596664429\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Training Accuracy:\", history.history[\"accuracy\"][-1])\n",
    "print(\"Final Validation Accuracy:\", history.history[\"val_accuracy\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "86cd1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_k(img_path, k=3, min_conf=0.05):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    preds = model.predict(img_array)[0]\n",
    "    top_indices = preds.argsort()[-k:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        conf = float(preds[idx])\n",
    "        if conf >= min_conf:\n",
    "            results.append({\n",
    "                \"disease\": label_map[idx],\n",
    "                \"confidence\": round(conf * 100, 2)\n",
    "            })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a4fa3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(base_cost, severity):\n",
    "    low, high = base_cost\n",
    "\n",
    "    multiplier = {\n",
    "        \"Low\": 0.8,\n",
    "        \"Medium\": 1.0,\n",
    "        \"High\": 1.4\n",
    "    }.get(severity, 1.0)\n",
    "\n",
    "    est_low = int(low * multiplier)\n",
    "    est_high = int(high * multiplier)\n",
    "\n",
    "    if est_high < 300:\n",
    "        tier = \"â‚¹ Low\"\n",
    "    elif est_high < 700:\n",
    "        tier = \"â‚¹â‚¹ Medium\"\n",
    "    else:\n",
    "        tier = \"â‚¹â‚¹â‚¹ High\"\n",
    "\n",
    "    return {\n",
    "        \"range\": f\"â‚¹{est_low} â€“ â‚¹{est_high}\",\n",
    "        \"tier\": tier\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d15fa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_severity_from_heatmap(heatmap_path):\n",
    "    heatmap = cv2.imread(heatmap_path)\n",
    "    heatmap_gray = cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold to isolate \"hot\" infected zones\n",
    "    _, binary_map = cv2.threshold(heatmap_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    infected_area = np.sum(binary_map == 255)\n",
    "    total_area = binary_map.shape[0] * binary_map.shape[1]\n",
    "\n",
    "    ratio = infected_area / total_area\n",
    "\n",
    "    if ratio < 0.10:\n",
    "        severity = \"Low\"\n",
    "    elif ratio < 0.40:\n",
    "        severity = \"Medium\"\n",
    "    else:\n",
    "        severity = \"High\"\n",
    "\n",
    "    return {\n",
    "        \"severity\": severity,\n",
    "        \"infected_ratio\": round(ratio * 100, 2)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7409b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dosage(base_dosage, severity):\n",
    "    value, unit = base_dosage.split()\n",
    "    value = float(value)\n",
    "\n",
    "    multiplier = {\n",
    "        \"Low\": 0.7,\n",
    "        \"Medium\": 1.0,\n",
    "        \"High\": 1.3\n",
    "    }.get(severity, 1.0)\n",
    "\n",
    "    adjusted = round(value * multiplier, 2)\n",
    "    return f\"{adjusted} {unit}\"\n",
    "\n",
    "def get_remediation_plan(disease_name, severity=\"Low\", preference=\"organic\"):\n",
    "    data = REMEDIATION_DB.get(disease_name)\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    treatment = data.get(preference, data[\"organic\"])\n",
    "\n",
    "    adjusted_dosage = adjust_dosage(treatment[\"dosage\"], severity)\n",
    "    cost_info = estimate_cost(treatment[\"base_cost\"], severity)\n",
    "\n",
    "    escalate = severity == \"High\"\n",
    "\n",
    "    return {\n",
    "        \"mode\": preference,\n",
    "        \"urgency\": treatment[\"urgency\"],\n",
    "        \"treatment_steps\": treatment[\"steps\"],\n",
    "        \"dosage\": adjusted_dosage,\n",
    "        \"application_frequency\": treatment[\"frequency\"],\n",
    "        \"max_limit\": treatment[\"max_limit\"],\n",
    "        \"cost_range\": cost_info[\"range\"],\n",
    "        \"cost_tier\": cost_info[\"tier\"],\n",
    "        \"prevention_tips\": data[\"prevention\"],\n",
    "        \"safety_warnings\": data[\"safety\"],\n",
    "        \"escalate_to_expert\": escalate\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5a73f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_predict_with_heatmap(img_path, treatment_mode=\"organic\"):\n",
    "    result = predict_disease(img_path)\n",
    "\n",
    "    if result[\"status\"] != \"success\":\n",
    "        return result\n",
    "\n",
    "    if result.get(\"is_healthy\"):\n",
    "        result[\"message\"] = \"No treatment required. Your plant is healthy.\"\n",
    "        result[\"remediation\"] = None\n",
    "        result[\"severity\"] = \"None\"\n",
    "        result[\"infected_ratio\"] = 0.0\n",
    "        return result\n",
    "\n",
    "    heatmap_path = generate_gradcam(model, img_path)\n",
    "    severity_info = estimate_severity_from_heatmap(heatmap_path)\n",
    "\n",
    "    # ğŸ”¥ NEW: Draw bounding boxes\n",
    "    boxed_image_path, spot_count = draw_real_lesion_boxes(img_path)\n",
    "\n",
    "    remediation = get_remediation_plan(\n",
    "        result[\"disease\"],\n",
    "        severity_info[\"severity\"],\n",
    "        treatment_mode\n",
    "    )\n",
    "\n",
    "    result[\"heatmap\"] = heatmap_path\n",
    "    result[\"boxed_image\"] = boxed_image_path\n",
    "    result[\"spot_count\"] = spot_count\n",
    "    result[\"severity\"] = severity_info[\"severity\"]\n",
    "    result[\"infected_ratio\"] = severity_info[\"infected_ratio\"]\n",
    "    result[\"remediation\"] = remediation\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4db4e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_result(result):\n",
    "    print(\"\\n========== AI CROP DIAGNOSIS REPORT ==========\\n\")\n",
    "\n",
    "    print(f\"Status           : {result.get('status')}\")\n",
    "    print(f\"Disease          : {result.get('disease')}\")\n",
    "    print(f\"Healthy          : {result.get('is_healthy')}\")\n",
    "    print(f\"Confidence       : {result.get('confidence')} %\")\n",
    "    print(f\"Severity         : {result.get('severity')}\")\n",
    "    print(f\"Infected Ratio   : {result.get('infected_ratio')} %\")\n",
    "\n",
    "    if \"remediation\" in result and result[\"remediation\"] is not None:\n",
    "        r = result[\"remediation\"]   # ğŸ”¥ DEFINE FIRST\n",
    "\n",
    "        print(\"\\n--- Remediation Plan ---\")\n",
    "        print(f\"Mode             : {r.get('mode')}\")\n",
    "        print(f\"Urgency          : {r.get('urgency')}\")\n",
    "        print(f\"Dosage           : {r.get('dosage')}\")\n",
    "        print(f\"Frequency        : {r.get('application_frequency')}\")\n",
    "        print(f\"Max Limit        : {r.get('max_limit')}\")\n",
    "        print(f\"Cost Range       : {r.get('cost_range')}\")\n",
    "        print(f\"Cost Tier        : {r.get('cost_tier')}\")\n",
    "        print(f\"Infected Spots  : {result.get('spot_count')}\")\n",
    "        print(f\"Boxed Image     : {result.get('boxed_image')}\")\n",
    "\n",
    "\n",
    "        print(\"\\nTreatment Steps:\")\n",
    "        for i, step in enumerate(r.get(\"treatment_steps\", []), 1):\n",
    "            print(f\"  {i}. {step}\")\n",
    "\n",
    "        print(\"\\nPrevention Tips:\")\n",
    "        for tip in r.get(\"prevention_tips\", []):\n",
    "            print(f\"  - {tip}\")\n",
    "\n",
    "        print(\"\\nSafety Warnings:\")\n",
    "        for warn in r.get(\"safety_warnings\", []):\n",
    "            print(f\"  âš  {warn}\")\n",
    "\n",
    "        print(f\"\\nEscalate to Expert : {'Yes' if r.get('escalate_to_expert') else 'No'}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo treatment required.\")\n",
    "\n",
    "    print(\"\\n=============================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45c2bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : Low\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 2.1 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹80 â€“ â‚¹200\n",
      "Cost Tier        : â‚¹ Low\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : No\n",
      "\n",
      "=============================================\n",
      "\n",
      "Boxed output saved as: boxed_output.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    TEST_IMAGE = r'0a8a68ee-f587-4dea-beec-79d02e7d3fa4___RS_Early.B 8461.JPG'\n",
    "    result = full_predict_with_heatmap(TEST_IMAGE, \"organic\")\n",
    "    pretty_print_result(result)\n",
    "\n",
    "    print(\"Boxed output saved as:\", result[\"boxed_image\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2496158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Low Severity / Organic Mode ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : Low\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 2.1 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹80 â€“ â‚¹200\n",
      "Cost Tier        : â‚¹ Low\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : No\n",
      "\n",
      "=============================================\n",
      "\n",
      "\n",
      "--- Medium Severity / Organic Mode ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : Medium\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 3.0 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹100 â€“ â‚¹250\n",
      "Cost Tier        : â‚¹ Low\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : No\n",
      "\n",
      "=============================================\n",
      "\n",
      "\n",
      "--- High Severity / Organic Mode ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : High\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 3.9 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹140 â€“ â‚¹350\n",
      "Cost Tier        : â‚¹â‚¹ Medium\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : Yes\n",
      "\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sev in [\"Low\", \"Medium\", \"High\"]:\n",
    "    print(f\"\\n--- {sev} Severity / Organic Mode ---\")\n",
    "    severity_override = {\"Low\": 0.05, \"Medium\": 0.25, \"High\": 0.55}[sev]\n",
    "\n",
    "    result = full_predict_with_heatmap(TEST_IMAGE, \"organic\")\n",
    "    result[\"severity\"] = sev  # simulate severity\n",
    "    result[\"remediation\"] = get_remediation_plan(\n",
    "        result[\"disease\"], sev, \"organic\"\n",
    "    )\n",
    "\n",
    "    pretty_print_result(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6495ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
