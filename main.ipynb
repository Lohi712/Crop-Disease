{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3b4cb9",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import cv2  \n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATASET_PATH = BASE_DIR / \"dataset_filtered\"\n",
    "LABEL_MAP = BASE_DIR / \"label_map.txt\"\n",
    "MODEL_NAME = BASE_DIR / \"crop_disease_model.keras\"\n",
    "EPOCHS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8979ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset folder not found at {DATASET_PATH}\\n\"\n",
    "        \"Please download the dataset and place it in the project root as 'dataset_filtered/'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac4a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d57a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6961d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16254 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26dd404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4058 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = val_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08aec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label map saved to d:\\Lohith\\BTECH CODES\\Machine_Learning\\Project\\Crop-Disease\\label_map.txt\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = train_data.num_classes\n",
    "labels = train_data.class_indices\n",
    "with open(LABEL_MAP, \"w\") as f:\n",
    "    for label, idx in labels.items():\n",
    "        f.write(f\"{idx}:{label}\\n\")\n",
    "\n",
    "print(\"âœ… Label map saved to\", LABEL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c0730",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURE AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c6d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f20e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c809fd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m327,936\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             â”‚         \u001b[38;5;34m3,341\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,589,261</span> (9.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,589,261\u001b[0m (9.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,277</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,277\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bba55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(1.5628846153846154), 1: np.float64(1.5628846153846154), 2: np.float64(10.2484237074401), 3: np.float64(0.7346108650456477), 4: np.float64(1.5628846153846154), 5: np.float64(0.8182641965364479), 6: np.float64(1.6408237431859478), 7: np.float64(0.8823625210357744), 8: np.float64(0.9323696437790397), 9: np.float64(1.1123733917328222), 10: np.float64(0.29171901360422126), 11: np.float64(4.181631077952148), 12: np.float64(0.9821741494954378)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_data.classes),\n",
    "    y=train_data.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c568a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(MODEL_NAME, save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4765566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m  4/508\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8:16\u001b[0m 985ms/step - accuracy: 0.0664 - loss: 3.0022"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal Training Accuracy:\u001b[39m\u001b[33m\"\u001b[39m, history.history[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "print(\"Final Training Accuracy:\", history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94ddc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final model saved\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)\n",
    "print(\"âœ… Final model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f40fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "with open(LABEL_MAP, \"r\") as f:\n",
    "    for line in f:\n",
    "        idx, label = line.strip().split(\":\")\n",
    "        label_map[int(idx)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82658ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMEDIATION_DB = {\n",
    "    \"Potato___Early_blight\": {\n",
    "        \"organic\": {\n",
    "            \"urgency\": \"Monitor & apply organic remedies.\",\n",
    "            \"steps\": [\n",
    "                \"Remove infected leaves\",\n",
    "                \"Spray neem oil\",\n",
    "                \"Improve air circulation\"\n",
    "            ],\n",
    "            \"dosage\": \"3 ml/L\",\n",
    "            \"frequency\": \"Once every 7 days\",\n",
    "            \"max_limit\": \"Do not exceed 5 ml/L\",\n",
    "            \"base_cost\": (100, 250)   # ğŸ”¥ NEW\n",
    "        },\n",
    "        \"chemical\": {\n",
    "            \"urgency\": \"Apply fungicide immediately.\",\n",
    "            \"steps\": [\n",
    "                \"Spray Mancozeb\",\n",
    "                \"Repeat after 7 days\",\n",
    "                \"Avoid irrigation for 24 hours\"\n",
    "            ],\n",
    "            \"dosage\": \"2 g/L\",\n",
    "            \"frequency\": \"Once every 7 days\",\n",
    "            \"max_limit\": \"Do not exceed 3 g/L\",\n",
    "            \"base_cost\": (250, 600)   # ğŸ”¥ NEW\n",
    "        },\n",
    "        \"prevention\": [\n",
    "            \"Avoid overhead irrigation\",\n",
    "            \"Use disease-resistant varieties\",\n",
    "            \"Crop rotation\"\n",
    "        ],\n",
    "        \"safety\": [\n",
    "            \"Wear gloves & mask\",\n",
    "            \"Do not spray during noon\",\n",
    "            \"Keep away from children\"\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6162aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 13), dtype=float32, numpy=\n",
       "array([[2.3558036e-06, 2.7145757e-07, 1.5208500e-06, 5.6277501e-04,\n",
       "        1.3047788e-05, 9.9529147e-01, 2.1486147e-05, 2.9396375e-03,\n",
       "        3.5104102e-05, 1.7340095e-05, 7.0359831e-04, 1.2451320e-05,\n",
       "        3.9906017e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(MODEL_NAME)\n",
    "\n",
    "dummy_input = np.zeros((1, 224, 224, 3), dtype=np.float32)\n",
    "model(dummy_input)  # ğŸ‘ˆ IMPORTANT: call model directly, not predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a585647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blurry(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    variance = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    threshold = 100.0  # You can adjust this threshold\n",
    "    return variance < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0699a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradcam(model, img_path, layer_name=None):\n",
    "    \"\"\"Generate a Grad-CAM heatmap overlay for the predicted class.\n",
    "\n",
    "    Fixes Keras graph issues by building the Grad-CAM model using the\n",
    "    MobileNetV2 base model's input graph (not Sequential's symbolic tensors).\n",
    "    \"\"\"\n",
    "    base_model = model.layers[0]  # MobileNetV2 (Functional)\n",
    "\n",
    "    # Pick a sensible conv layer if not provided\n",
    "    if layer_name is None:\n",
    "        for layer in reversed(base_model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer_name = layer.name\n",
    "                break\n",
    "        if layer_name is None:\n",
    "            # Fallback: any layer with 'conv' in its name\n",
    "            for layer in reversed(base_model.layers):\n",
    "                if \"conv\" in layer.name.lower():\n",
    "                    layer_name = layer.name\n",
    "                    break\n",
    "\n",
    "    if layer_name is None:\n",
    "        raise ValueError(\"No convolutional layer found in base model.\")\n",
    "\n",
    "    conv_layer = base_model.get_layer(layer_name)\n",
    "\n",
    "    # Build a Grad-CAM graph rooted at base_model.input to avoid tensor mismatch\n",
    "    x = base_model.output\n",
    "    for head_layer in model.layers[1:]:\n",
    "        x = head_layer(x)\n",
    "    preds = x\n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=[conv_layer.output, preds],\n",
    "    )\n",
    "\n",
    "    # Load and preprocess image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0).astype(np.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(pooled_grads * conv_outputs, axis=-1)\n",
    "\n",
    "    # Convert to numpy once, then use numpy/cv2 safely\n",
    "    heatmap = heatmap.numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= (np.max(heatmap) + 1e-8)\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (224, 224))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    original = cv2.imread(img_path)\n",
    "    if original is None:\n",
    "        raise FileNotFoundError(f\"Could not read image from path: {img_path}\")\n",
    "    original = cv2.resize(original, (224, 224))\n",
    "\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(original, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    output_path = \"heatmap_output.jpg\"\n",
    "    cv2.imwrite(output_path, overlay)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9769f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_real_lesion_boxes(img_path):\n",
    "    original = cv2.imread(img_path)\n",
    "    if original is None:\n",
    "        raise FileNotFoundError(\"Image not found\")\n",
    "\n",
    "    hsv = cv2.cvtColor(original, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Brown / yellow lesion color range\n",
    "    lower = np.array([5, 40, 40])\n",
    "    upper = np.array([35, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    # Morph cleanup\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 250:  # reject noise\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w > 15 and h > 15:\n",
    "                boxes.append((x, y, w, h))\n",
    "\n",
    "    # Draw boxes\n",
    "    for (x, y, w, h) in boxes:\n",
    "        cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    output_path = \"boxed_output.jpg\"\n",
    "    cv2.imwrite(output_path, original)\n",
    "\n",
    "    return output_path, len(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "80bc4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disease(img_path, confidence_threshold=0.45):\n",
    "    if is_blurry(img_path):\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": \"Image is too blurry. Please retake photo.\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    \n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    preds = model.predict(img_array)[0]\n",
    "    top_idx = np.argmax(preds)\n",
    "    confidence = float(preds[top_idx])\n",
    "    disease_name = label_map[top_idx]\n",
    "\n",
    "    # Epic 3: Unknown/Unclear Result Story\n",
    "    if confidence < confidence_threshold:\n",
    "        return {\n",
    "            \"status\": \"unknown\",\n",
    "            \"disease\": \"Unknown/Unclear\",\n",
    "            \"message\": \"Please consult a human expert or retake the photo.\",\n",
    "            \"confidence\": round(confidence * 100, 2)\n",
    "        }\n",
    "    \n",
    "    # Epic 3: Healthy Plant Story\n",
    "    # Check if the predicted label contains the word \"healthy\"\n",
    "    is_healthy = \"healthy\" in disease_name.lower()\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"disease\": disease_name,\n",
    "        \"is_healthy\": is_healthy,\n",
    "        \"confidence\": round(confidence * 100, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3ecc9fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 0.9134982228279114\n",
      "Final Validation Accuracy: 0.9115327596664429\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Training Accuracy:\", history.history[\"accuracy\"][-1])\n",
    "print(\"Final Validation Accuracy:\", history.history[\"val_accuracy\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "86cd1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_k(img_path, k=3, min_conf=0.05):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    preds = model.predict(img_array)[0]\n",
    "    top_indices = preds.argsort()[-k:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        conf = float(preds[idx])\n",
    "        if conf >= min_conf:\n",
    "            results.append({\n",
    "                \"disease\": label_map[idx],\n",
    "                \"confidence\": round(conf * 100, 2)\n",
    "            })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a4fa3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(base_cost, severity):\n",
    "    low, high = base_cost\n",
    "\n",
    "    multiplier = {\n",
    "        \"Low\": 0.8,\n",
    "        \"Medium\": 1.0,\n",
    "        \"High\": 1.4\n",
    "    }.get(severity, 1.0)\n",
    "\n",
    "    est_low = int(low * multiplier)\n",
    "    est_high = int(high * multiplier)\n",
    "\n",
    "    if est_high < 300:\n",
    "        tier = \"â‚¹ Low\"\n",
    "    elif est_high < 700:\n",
    "        tier = \"â‚¹â‚¹ Medium\"\n",
    "    else:\n",
    "        tier = \"â‚¹â‚¹â‚¹ High\"\n",
    "\n",
    "    return {\n",
    "        \"range\": f\"â‚¹{est_low} â€“ â‚¹{est_high}\",\n",
    "        \"tier\": tier\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d15fa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_severity_from_heatmap(heatmap_path):\n",
    "    heatmap = cv2.imread(heatmap_path)\n",
    "    heatmap_gray = cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold to isolate \"hot\" infected zones\n",
    "    _, binary_map = cv2.threshold(heatmap_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    infected_area = np.sum(binary_map == 255)\n",
    "    total_area = binary_map.shape[0] * binary_map.shape[1]\n",
    "\n",
    "    ratio = infected_area / total_area\n",
    "\n",
    "    if ratio < 0.10:\n",
    "        severity = \"Low\"\n",
    "    elif ratio < 0.40:\n",
    "        severity = \"Medium\"\n",
    "    else:\n",
    "        severity = \"High\"\n",
    "\n",
    "    return {\n",
    "        \"severity\": severity,\n",
    "        \"infected_ratio\": round(ratio * 100, 2)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7409b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dosage(base_dosage, severity):\n",
    "    value, unit = base_dosage.split()\n",
    "    value = float(value)\n",
    "\n",
    "    multiplier = {\n",
    "        \"Low\": 0.7,\n",
    "        \"Medium\": 1.0,\n",
    "        \"High\": 1.3\n",
    "    }.get(severity, 1.0)\n",
    "\n",
    "    adjusted = round(value * multiplier, 2)\n",
    "    return f\"{adjusted} {unit}\"\n",
    "\n",
    "def get_remediation_plan(disease_name, severity=\"Low\", preference=\"organic\"):\n",
    "    data = REMEDIATION_DB.get(disease_name)\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    treatment = data.get(preference, data[\"organic\"])\n",
    "\n",
    "    adjusted_dosage = adjust_dosage(treatment[\"dosage\"], severity)\n",
    "    cost_info = estimate_cost(treatment[\"base_cost\"], severity)\n",
    "\n",
    "    escalate = severity == \"High\"\n",
    "\n",
    "    return {\n",
    "        \"mode\": preference,\n",
    "        \"urgency\": treatment[\"urgency\"],\n",
    "        \"treatment_steps\": treatment[\"steps\"],\n",
    "        \"dosage\": adjusted_dosage,\n",
    "        \"application_frequency\": treatment[\"frequency\"],\n",
    "        \"max_limit\": treatment[\"max_limit\"],\n",
    "        \"cost_range\": cost_info[\"range\"],\n",
    "        \"cost_tier\": cost_info[\"tier\"],\n",
    "        \"prevention_tips\": data[\"prevention\"],\n",
    "        \"safety_warnings\": data[\"safety\"],\n",
    "        \"escalate_to_expert\": escalate\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5a73f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_predict_with_heatmap(img_path, treatment_mode=\"organic\"):\n",
    "    result = predict_disease(img_path)\n",
    "\n",
    "    if result[\"status\"] != \"success\":\n",
    "        return result\n",
    "\n",
    "    if result.get(\"is_healthy\"):\n",
    "        result[\"message\"] = \"No treatment required. Your plant is healthy.\"\n",
    "        result[\"remediation\"] = None\n",
    "        result[\"severity\"] = \"None\"\n",
    "        result[\"infected_ratio\"] = 0.0\n",
    "        return result\n",
    "\n",
    "    heatmap_path = generate_gradcam(model, img_path)\n",
    "    severity_info = estimate_severity_from_heatmap(heatmap_path)\n",
    "\n",
    "    # ğŸ”¥ NEW: Draw bounding boxes\n",
    "    boxed_image_path, spot_count = draw_real_lesion_boxes(img_path)\n",
    "\n",
    "    remediation = get_remediation_plan(\n",
    "        result[\"disease\"],\n",
    "        severity_info[\"severity\"],\n",
    "        treatment_mode\n",
    "    )\n",
    "\n",
    "    result[\"heatmap\"] = heatmap_path\n",
    "    result[\"boxed_image\"] = boxed_image_path\n",
    "    result[\"spot_count\"] = spot_count\n",
    "    result[\"severity\"] = severity_info[\"severity\"]\n",
    "    result[\"infected_ratio\"] = severity_info[\"infected_ratio\"]\n",
    "    result[\"remediation\"] = remediation\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4db4e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_result(result):\n",
    "    print(\"\\n========== AI CROP DIAGNOSIS REPORT ==========\\n\")\n",
    "\n",
    "    print(f\"Status           : {result.get('status')}\")\n",
    "    print(f\"Disease          : {result.get('disease')}\")\n",
    "    print(f\"Healthy          : {result.get('is_healthy')}\")\n",
    "    print(f\"Confidence       : {result.get('confidence')} %\")\n",
    "    print(f\"Severity         : {result.get('severity')}\")\n",
    "    print(f\"Infected Ratio   : {result.get('infected_ratio')} %\")\n",
    "\n",
    "    if \"remediation\" in result and result[\"remediation\"] is not None:\n",
    "        r = result[\"remediation\"]   # ğŸ”¥ DEFINE FIRST\n",
    "\n",
    "        print(\"\\n--- Remediation Plan ---\")\n",
    "        print(f\"Mode             : {r.get('mode')}\")\n",
    "        print(f\"Urgency          : {r.get('urgency')}\")\n",
    "        print(f\"Dosage           : {r.get('dosage')}\")\n",
    "        print(f\"Frequency        : {r.get('application_frequency')}\")\n",
    "        print(f\"Max Limit        : {r.get('max_limit')}\")\n",
    "        print(f\"Cost Range       : {r.get('cost_range')}\")\n",
    "        print(f\"Cost Tier        : {r.get('cost_tier')}\")\n",
    "        print(f\"Infected Spots  : {result.get('spot_count')}\")\n",
    "        print(f\"Boxed Image     : {result.get('boxed_image')}\")\n",
    "\n",
    "\n",
    "        print(\"\\nTreatment Steps:\")\n",
    "        for i, step in enumerate(r.get(\"treatment_steps\", []), 1):\n",
    "            print(f\"  {i}. {step}\")\n",
    "\n",
    "        print(\"\\nPrevention Tips:\")\n",
    "        for tip in r.get(\"prevention_tips\", []):\n",
    "            print(f\"  - {tip}\")\n",
    "\n",
    "        print(\"\\nSafety Warnings:\")\n",
    "        for warn in r.get(\"safety_warnings\", []):\n",
    "            print(f\"  âš  {warn}\")\n",
    "\n",
    "        print(f\"\\nEscalate to Expert : {'Yes' if r.get('escalate_to_expert') else 'No'}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo treatment required.\")\n",
    "\n",
    "    print(\"\\n=============================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45c2bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : Low\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 2.1 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹80 â€“ â‚¹200\n",
      "Cost Tier        : â‚¹ Low\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : No\n",
      "\n",
      "=============================================\n",
      "\n",
      "Boxed output saved as: boxed_output.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    TEST_IMAGE = r'0a8a68ee-f587-4dea-beec-79d02e7d3fa4___RS_Early.B 8461.JPG'\n",
    "    result = full_predict_with_heatmap(TEST_IMAGE, \"organic\")\n",
    "    pretty_print_result(result)\n",
    "\n",
    "    print(\"Boxed output saved as:\", result[\"boxed_image\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2496158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Low Severity / Organic Mode ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : Low\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 2.1 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹80 â€“ â‚¹200\n",
      "Cost Tier        : â‚¹ Low\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : No\n",
      "\n",
      "=============================================\n",
      "\n",
      "\n",
      "--- Medium Severity / Organic Mode ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : Medium\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 3.0 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹100 â€“ â‚¹250\n",
      "Cost Tier        : â‚¹ Low\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : No\n",
      "\n",
      "=============================================\n",
      "\n",
      "\n",
      "--- High Severity / Organic Mode ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\n",
      "========== AI CROP DIAGNOSIS REPORT ==========\n",
      "\n",
      "Status           : success\n",
      "Disease          : Potato___Early_blight\n",
      "Healthy          : False\n",
      "Confidence       : 100.0 %\n",
      "Severity         : High\n",
      "Infected Ratio   : 1.24 %\n",
      "\n",
      "--- Remediation Plan ---\n",
      "Mode             : organic\n",
      "Urgency          : Monitor & apply organic remedies.\n",
      "Dosage           : 3.9 ml/L\n",
      "Frequency        : Once every 7 days\n",
      "Max Limit        : Do not exceed 5 ml/L\n",
      "Cost Range       : â‚¹140 â€“ â‚¹350\n",
      "Cost Tier        : â‚¹â‚¹ Medium\n",
      "Infected Spots  : 7\n",
      "Boxed Image     : boxed_output.jpg\n",
      "\n",
      "Treatment Steps:\n",
      "  1. Remove infected leaves\n",
      "  2. Spray neem oil\n",
      "  3. Improve air circulation\n",
      "\n",
      "Prevention Tips:\n",
      "  - Avoid overhead irrigation\n",
      "  - Use disease-resistant varieties\n",
      "  - Crop rotation\n",
      "\n",
      "Safety Warnings:\n",
      "  âš  Wear gloves & mask\n",
      "  âš  Do not spray during noon\n",
      "  âš  Keep away from children\n",
      "\n",
      "Escalate to Expert : Yes\n",
      "\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sev in [\"Low\", \"Medium\", \"High\"]:\n",
    "    print(f\"\\n--- {sev} Severity / Organic Mode ---\")\n",
    "    severity_override = {\"Low\": 0.05, \"Medium\": 0.25, \"High\": 0.55}[sev]\n",
    "\n",
    "    result = full_predict_with_heatmap(TEST_IMAGE, \"organic\")\n",
    "    result[\"severity\"] = sev  # simulate severity\n",
    "    result[\"remediation\"] = get_remediation_plan(\n",
    "        result[\"disease\"], sev, \"organic\"\n",
    "    )\n",
    "\n",
    "    pretty_print_result(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6495ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
